{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import funcs.utils as utils\n",
    "import funcs.plotting as plot\n",
    "import funcs.amyloid as amyloid\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSED_DIR = \"data/processed\"\n",
    "RANDOM_STATE = 123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load Data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw Data\n",
    "data_df = pd.read_csv(os.path.join(PROCESSED_DIR, \"dataset_processed.tsv\"), sep='\\t', index_col=0).rename(columns=amyloid.ddict_unclean)\n",
    "\n",
    "# Fix Dates\n",
    "data_df = pd.concat([pd.to_datetime(data_df[amyloid.dates][var], format=\"mixed\") for var in amyloid.dates], axis=1, keys=amyloid.dates).join(\n",
    "    data_df.drop(amyloid.dates, axis=1)  \n",
    ")\n",
    "\n",
    "# Not imputed\n",
    "X = pd.read_csv(os.path.join(PROCESSED_DIR, \"AL_for_ccp_02.tsv\"), sep='\\t', index_col=0).rename(columns=amyloid.ddict_unclean)\n",
    "\n",
    "# Imputed\n",
    "Xi_median = pd.read_csv(\"data/imputed/median_qvars_01.tsv\", sep=\"\\t\", index_col=0).rename(columns=amyloid.ddict_unclean)\n",
    "Xi_knn = pd.read_csv(\"data/imputed/knn_qvars_01.tsv\", sep=\"\\t\", index_col=0).rename(columns=amyloid.ddict_unclean)\n",
    "Xi_mice = pd.read_csv(\"data/imputed/mice_qvars_05.tsv\", sep=\"\\t\").rename(columns={'X24_hr_UTP':'24_hr_UTP'}).rename(columns=amyloid.ddict_unclean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clusters from consensus cluster plus\n",
    "ccp_cluster_df = pd.read_csv(os.path.join(PROCESSED_DIR,\"AL_with_ccp_03.tsv\"), sep=\"\\t\", index_col=0)[[\"cluster\",\"itemConsensus\"]].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Survival Predictons\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import set_config\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sksurv.datasets import load_gbsg2\n",
    "from sksurv.preprocessing import OneHotEncoder\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "\n",
    "from sksurv.metrics import (\n",
    "    concordance_index_censored,\n",
    "    concordance_index_ipcw,\n",
    "    cumulative_dynamic_auc,\n",
    "    integrated_brier_score,\n",
    ")\n",
    "\n",
    "# Initial model just with quantitative variables\n",
    "random_state = 20\n",
    "test_size = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 29 quantitative variables.\n",
      "Using 35 categorical variables.\n",
      "Total samples: n=1601\n"
     ]
    }
   ],
   "source": [
    "# Drop due to high missingness\n",
    "to_drop = [\"Amyloid type\",\"Secondary organ\",\"Arrhythmia \",\"(Autonomic)\",\n",
    "           \"(Peripheral)\",\"SIFE M-component\",\"UIFE M-component\",\n",
    "           \"Education\",\"Abdominal fat pad CR staining\", \"Bone marrow CR staining\"]\n",
    "\n",
    "Xi_mice_cat = Xi_mice.join(data_df.loc[Xi_mice.index, amyloid.catvars]).join(ccp_cluster_df['cluster']).drop(columns=to_drop).dropna()\n",
    "\n",
    "# Collapse Race\n",
    "Xi_mice_cat[\"Race\"] = Xi_mice_cat[\"Race\"].apply(lambda x: \"Other\" if x in ['American_Indian_Alaska_Native','Multiracial','Native_Hawaiian_Pacific', 'Unknown/other'] else x)\n",
    "\n",
    "# Compute BU Staging with imputed values\n",
    "Xi_mice_cat[\"BU Stage (Computed)\"] = Xi_mice_cat.apply(lambda row: utils.assign_bu_stage(row), 1)\n",
    "\n",
    "# Ensure Cluster is categorical\n",
    "Xi_mice_cat[\"cluster\"] = Xi_mice_cat[\"cluster\"].astype(str)\n",
    "\n",
    "# Split to categorical variables\n",
    "n_cat = Xi_mice_cat.loc[:,Xi_mice_cat.dtypes == \"object\"].columns\n",
    "n_numeric = Xi_mice_cat.loc[:,Xi_mice_cat.dtypes != \"object\"].columns\n",
    "\n",
    "Xi_mice_cat = OneHotEncoder().fit_transform(Xi_mice_cat.loc[:,n_cat].astype(\"category\")).join(Xi_mice_cat.loc[:,n_numeric])\n",
    "\n",
    "print(\"Using {} quantitative variables.\".format(n_numeric.shape[0]))\n",
    "print(\"Using {} categorical variables.\".format(n_cat.shape[0]))\n",
    "print(\"Total samples: n={}\".format(Xi_mice_cat.shape[0]))\n",
    "\n",
    "# Join outcome variables (time, status) and cluster\n",
    "Xi_mice_bu_df = Xi_mice_cat.join(data_df[[\"time\",\"status\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2a. Baseline Cox Regression Models\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.25\n",
    "RANDOM_STATE=122"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size (n=1200)\n",
      "Test size (n=401)\n"
     ]
    }
   ],
   "source": [
    "# Generate outcome \n",
    "y = Xi_mice_bu_df.loc[:,['status','time']]\n",
    "y.loc[:,'status'] = y['status'].replace({1:True,0:False})\n",
    "y = np.array(list(y.to_records(index=False)))\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xi_mice_bu_df.drop(columns=['time','status']), y, test_size=test_size, random_state=RANDOM_STATE)\n",
    "\n",
    "print(\"Train size (n={})\".format(X_train.shape[0]))\n",
    "print(\"Test size (n={})\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C-statistic (Train):  0.7033329440717625\n",
      "C-statistic (Test):  0.6906285667699331\n"
     ]
    }
   ],
   "source": [
    "numerical_vars = [\"Age\",\"eGFR\",\"Troponin\"]\n",
    "categorical_vars = [\"Sex\",\"Race\",\"Primary organ\",\"BU Stage (Computed)\"]\n",
    "categorical_vars = list(chain(*[Xi_mice_bu_df.columns[Xi_mice_bu_df.columns.str.startswith(cat)] for cat in categorical_vars]))\n",
    "vars_to_use = numerical_vars + categorical_vars\n",
    "\n",
    "# Fit Cox Regression\n",
    "cph = CoxPHSurvivalAnalysis()\n",
    "cph.fit(X_train[vars_to_use], y_train)\n",
    "\n",
    "# Predictions on Test Set\n",
    "print(\"C-statistic (Train): \", cph.score(X_train[vars_to_use], y_train))\n",
    "print(\"C-statistic (Test): \", cph.score(X_test[vars_to_use], y_test))\n",
    "\n",
    "# Predictions\n",
    "x_times = range(2,250,5)\n",
    "cph_risk_scores = cph.predict(X_test[vars_to_use])\n",
    "cph_auc, cph_mean_auc = cumulative_dynamic_auc(y_train, y_test, cph_risk_scores, x_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C-statistic (Train):  0.7120264524863001\n",
      "C-statistic (Test):  0.702735203000163\n"
     ]
    }
   ],
   "source": [
    "numerical_vars = [\"Age\",\"eGFR\",\"Troponin\"]\n",
    "categorical_vars = [\"Sex\",\"Race\",\"Primary organ\",\"BU Stage (Computed)\",\"cluster\"]\n",
    "categorical_vars = list(chain(*[Xi_mice_bu_df.columns[Xi_mice_bu_df.columns.str.startswith(cat)] for cat in categorical_vars]))\n",
    "vars_to_use = numerical_vars + categorical_vars\n",
    "\n",
    "# Fit Cox Regression\n",
    "cph2 = CoxPHSurvivalAnalysis()\n",
    "cph2.fit(X_train[vars_to_use], y_train)\n",
    "\n",
    "# Predictions on Test Set\n",
    "print(\"C-statistic (Train): \", cph2.score(X_train[vars_to_use], y_train))\n",
    "print(\"C-statistic (Test): \", cph2.score(X_test[vars_to_use], y_test))\n",
    "\n",
    "# Predictions\n",
    "x_times = range(2,250,5)\n",
    "cph2_risk_scores = cph2.predict(X_test[vars_to_use])\n",
    "cph2_auc, cph2_mean_auc = cumulative_dynamic_auc(y_train, y_test, cph2_risk_scores, x_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C-statistic (Train):  0.652424018303944\n",
      "C-statistic (Test):  0.6436389205935105\n"
     ]
    }
   ],
   "source": [
    "numerical_vars = []\n",
    "categorical_vars = [\"BU Stage (Computed)\"]\n",
    "categorical_vars = list(chain(*[Xi_mice_bu_df.columns[Xi_mice_bu_df.columns.str.startswith(cat)] for cat in categorical_vars]))\n",
    "vars_to_use = numerical_vars + categorical_vars\n",
    "\n",
    "# Fit Cox Regression\n",
    "cph3 = CoxPHSurvivalAnalysis()\n",
    "cph3.fit(X_train[vars_to_use], y_train)\n",
    "\n",
    "# Predictions on Test Set\n",
    "print(\"C-statistic (Train): \", cph3.score(X_train[vars_to_use], y_train))\n",
    "print(\"C-statistic (Test): \", cph3.score(X_test[vars_to_use], y_test))\n",
    "\n",
    "# Predictions\n",
    "x_times = range(2,250,5)\n",
    "cph3_risk_scores = cph3.predict(X_test[vars_to_use])\n",
    "cph3_auc, cph3_mean_auc = cumulative_dynamic_auc(y_train, y_test, cph3_risk_scores, x_times)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2b. Random Survival Forest\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster=2.0\n",
      "cluster=3.0\n",
      "BU Stage (Computed)=stage II\n",
      "BU Stage (Computed)=stage III\n",
      "BU Stage (Computed)=stage IIIb\n"
     ]
    }
   ],
   "source": [
    "for x in X_train.columns:\n",
    "    if \"BU\" in x or \"cluster\" in x:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial RSF model, no hyperparameter search\n",
    "rsf = RandomSurvivalForest(\n",
    "    n_estimators=10, min_samples_split=10, min_samples_leaf=15, n_jobs=-1, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Fit Model\n",
    "rsf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on Test Set\n",
    "# Compute cumulative dynamic AUC\n",
    "x_times = range(2,250,5)\n",
    "rsf_risk_scores = rsf.predict(X_test)\n",
    "rsf_auc, rsf_mean_auc = cumulative_dynamic_auc(y_train, y_test, rsf_risk_scores, x_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_cumulative_dynamic_auc(x_times, rsf_auc, rsf_mean_auc)\n",
    "print(\"C-statistic (Train): \", rsf.score(X_train, y_train))\n",
    "print(\"C-statistic (Test): \", rsf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "result = permutation_importance(rsf, X_test, y_test, n_repeats=15, random_state=random_state)\n",
    "\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        k: result[k]\n",
    "        for k in (\n",
    "            \"importances_mean\",\n",
    "            \"importances_std\",\n",
    "        )\n",
    "    },\n",
    "    index=X_test.columns,\n",
    ").sort_values(by=\"importances_mean\", ascending=False).tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DataObject(object):\n",
    "#     \"\"\"_summary_\n",
    "\n",
    "#     Args:\n",
    "#         object (_type_): _description_\n",
    "#     \"\"\"\n",
    "#     def __init__(self, X: pd.DataFrame, time: str = \"time\", indicator: str = \"status\") -> None:\n",
    "#         \"\"\"_summary_\n",
    "\n",
    "#         Args:\n",
    "#             X (pd.DataFrame): _description_\n",
    "#             time (str, optional): _description_. Defaults to \"time\".\n",
    "#             indicator (str, optional): _description_. Defaults to \"status\".\n",
    "#         \"\"\"\n",
    "#         from sksurv.preprocessing import OneHotEncoder\n",
    "\n",
    "#         self.X = X\n",
    "\n",
    "#         # Select numeric and categorical variables\n",
    "#         self.X_cat = self.X.loc[:, self.X.dtypes in [\"object\",\"category\"]].astype(\"category\")\n",
    "#         self.X_numeric = self.X.loc[:, self.X.dtypes not in  [\"object\",\"category\"]]\n",
    "\n",
    "#         # One hot encode categorical variables\n",
    "#         self.X_cat_onehot = OneHotEncoder().fit_transform(self.X_cat)\n",
    "\n",
    "#     def __str__(self) -> str:\n",
    "#         print(\"Data Object \\n \\t * {} nategorical variables \\n \\t * {} numeric variables\".format(\n",
    "#             self.X_cat.shape[0], self.X_numeric.shape[0]))\n",
    "        \n",
    "# DataObject(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "r4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1cb7d89f10138752af65ef706fb595972ec9b0d7ed92a43a4be7d17426113632"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
